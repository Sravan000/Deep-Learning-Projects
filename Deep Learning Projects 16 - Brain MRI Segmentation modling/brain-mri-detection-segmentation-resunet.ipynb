{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033788,
     "end_time": "2020-11-17T11:51:36.923437",
     "exception": false,
     "start_time": "2020-11-17T11:51:36.889649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1: IMPORTING LIBRARIES AND DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-17T11:51:36.999480Z",
     "iopub.status.busy": "2020-11-17T11:51:36.998710Z",
     "iopub.status.idle": "2020-11-17T11:51:42.201035Z",
     "shell.execute_reply": "2020-11-17T11:51:42.202322Z"
    },
    "papermill": {
     "duration": 5.246427,
     "end_time": "2020-11-17T11:51:42.202572",
     "exception": false,
     "start_time": "2020-11-17T11:51:36.956145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import cv2\n",
    "from skimage import io\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import random\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:51:42.321859Z",
     "iopub.status.busy": "2020-11-17T11:51:42.320787Z",
     "iopub.status.idle": "2020-11-17T11:51:42.352886Z",
     "shell.execute_reply": "2020-11-17T11:51:42.353936Z"
    },
    "papermill": {
     "duration": 0.096735,
     "end_time": "2020-11-17T11:51:42.354108",
     "exception": false,
     "start_time": "2020-11-17T11:51:42.257373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:51:42.481224Z",
     "iopub.status.busy": "2020-11-17T11:51:42.479910Z",
     "iopub.status.idle": "2020-11-17T11:51:42.508175Z",
     "shell.execute_reply": "2020-11-17T11:51:42.509530Z"
    },
    "papermill": {
     "duration": 0.104987,
     "end_time": "2020-11-17T11:51:42.509726",
     "exception": false,
     "start_time": "2020-11-17T11:51:42.404739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:51:42.621182Z",
     "iopub.status.busy": "2020-11-17T11:51:42.620340Z",
     "iopub.status.idle": "2020-11-17T11:51:43.408122Z",
     "shell.execute_reply": "2020-11-17T11:51:43.409044Z"
    },
    "papermill": {
     "duration": 0.847747,
     "end_time": "2020-11-17T11:51:43.409215",
     "exception": false,
     "start_time": "2020-11-17T11:51:42.561468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_map = []\n",
    "for sub_dir_path in glob.glob(\"/kaggle/input/lgg-mri-segmentation/kaggle_3m/\"+\"*\"):\n",
    "    #if os.path.isdir(sub_path_dir):\n",
    "    try:\n",
    "        dir_name = sub_dir_path.split('/')[-1]\n",
    "        for filename in os.listdir(sub_dir_path):\n",
    "            image_path = sub_dir_path + '/' + filename\n",
    "            data_map.extend([dir_name, image_path])\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:51:43.492035Z",
     "iopub.status.busy": "2020-11-17T11:51:43.486631Z",
     "iopub.status.idle": "2020-11-17T11:51:43.495929Z",
     "shell.execute_reply": "2020-11-17T11:51:43.495338Z"
    },
    "papermill": {
     "duration": 0.051632,
     "end_time": "2020-11-17T11:51:43.496028",
     "exception": false,
     "start_time": "2020-11-17T11:51:43.444396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"patient_id\" : data_map[::2],\n",
    "                   \"path\" : data_map[1::2]})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:51:43.581896Z",
     "iopub.status.busy": "2020-11-17T11:51:43.581055Z",
     "iopub.status.idle": "2020-11-17T11:51:43.597442Z",
     "shell.execute_reply": "2020-11-17T11:51:43.596743Z"
    },
    "papermill": {
     "duration": 0.066446,
     "end_time": "2020-11-17T11:51:43.597570",
     "exception": false,
     "start_time": "2020-11-17T11:51:43.531124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_imgs = df[~df['path'].str.contains(\"mask\")]\n",
    "df_masks = df[df['path'].str.contains(\"mask\")]\n",
    "\n",
    "# File path line length images for later sorting\n",
    "BASE_LEN = 89 \n",
    "END_IMG_LEN = 4 \n",
    "END_MASK_LEN = 9 \n",
    "\n",
    "# Data sorting\n",
    "imgs = sorted(df_imgs[\"path\"].values, key=lambda x : int(x[BASE_LEN:-END_IMG_LEN]))\n",
    "masks = sorted(df_masks[\"path\"].values, key=lambda x : int(x[BASE_LEN:-END_MASK_LEN]))\n",
    "\n",
    "# Sorting check\n",
    "idx = random.randint(0, len(imgs)-1)\n",
    "print(\"Path to the Image:\", imgs[idx], \"\\nPath to the Mask:\", masks[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035551,
     "end_time": "2020-11-17T11:51:43.669365",
     "exception": false,
     "start_time": "2020-11-17T11:51:43.633814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### creating final datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:51:43.750115Z",
     "iopub.status.busy": "2020-11-17T11:51:43.749189Z",
     "iopub.status.idle": "2020-11-17T11:52:02.398369Z",
     "shell.execute_reply": "2020-11-17T11:52:02.397286Z"
    },
    "papermill": {
     "duration": 18.693607,
     "end_time": "2020-11-17T11:52:02.398488",
     "exception": false,
     "start_time": "2020-11-17T11:51:43.704881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Final dataframe\n",
    "brain_df = pd.DataFrame({\"patient_id\": df_imgs.patient_id.values,\n",
    "                         \"image_path\": imgs,\n",
    "                         \"mask_path\": masks\n",
    "                        })\n",
    "def pos_neg_diagnosis(mask_path):\n",
    "    value = np.max(cv2.imread(mask_path))\n",
    "    if value > 0 : \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "brain_df['mask'] = brain_df['mask_path'].apply(lambda x: pos_neg_diagnosis(x))\n",
    "brain_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037016,
     "end_time": "2020-11-17T11:52:02.473077",
     "exception": false,
     "start_time": "2020-11-17T11:52:02.436061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2: DATA VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:52:02.555857Z",
     "iopub.status.busy": "2020-11-17T11:52:02.554856Z",
     "iopub.status.idle": "2020-11-17T11:52:02.558861Z",
     "shell.execute_reply": "2020-11-17T11:52:02.559320Z"
    },
    "papermill": {
     "duration": 0.048756,
     "end_time": "2020-11-17T11:52:02.559448",
     "exception": false,
     "start_time": "2020-11-17T11:52:02.510692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain_df['mask'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:52:02.644005Z",
     "iopub.status.busy": "2020-11-17T11:52:02.643207Z",
     "iopub.status.idle": "2020-11-17T11:52:02.833551Z",
     "shell.execute_reply": "2020-11-17T11:52:02.834153Z"
    },
    "papermill": {
     "duration": 0.237416,
     "end_time": "2020-11-17T11:52:02.834320",
     "exception": false,
     "start_time": "2020-11-17T11:52:02.596904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go  # using plotly to create interactive plots\n",
    "\n",
    "fig = go.Figure([go.Bar(x=brain_df['mask'].value_counts().index, \n",
    "                        y=brain_df['mask'].value_counts(), \n",
    "                        width=[.4, .4]\n",
    "                       )\n",
    "                ])\n",
    "fig.update_traces(marker_color='rgb(158,202,225)', marker_line_color='rgb(8,48,107)',\n",
    "                  marker_line_width=4, opacity=0.4\n",
    "                 )\n",
    "fig.update_layout(title_text=\"Mask Count Plot\",\n",
    "                  width=700,\n",
    "                  height=550,\n",
    "                  yaxis=dict(\n",
    "                             title_text=\"Count\",\n",
    "                             tickmode=\"array\",\n",
    "                             titlefont=dict(size=20)\n",
    "                           )\n",
    "                 )\n",
    "fig.update_yaxes(automargin=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:52:02.921366Z",
     "iopub.status.busy": "2020-11-17T11:52:02.920613Z",
     "iopub.status.idle": "2020-11-17T11:52:03.836302Z",
     "shell.execute_reply": "2020-11-17T11:52:03.836804Z"
    },
    "papermill": {
     "duration": 0.962773,
     "end_time": "2020-11-17T11:52:03.836938",
     "exception": false,
     "start_time": "2020-11-17T11:52:02.874165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(brain_df)):\n",
    "    if cv2.imread(brain_df.mask_path[i]).max() > 0:\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(cv2.imread(brain_df.mask_path[i]));\n",
    "plt.title('Tumor Location')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(cv2.imread(brain_df.image_path[i]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:52:03.931589Z",
     "iopub.status.busy": "2020-11-17T11:52:03.930648Z",
     "iopub.status.idle": "2020-11-17T11:52:03.940073Z",
     "shell.execute_reply": "2020-11-17T11:52:03.939481Z"
    },
    "papermill": {
     "duration": 0.061063,
     "end_time": "2020-11-17T11:52:03.940187",
     "exception": false,
     "start_time": "2020-11-17T11:52:03.879124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv2.imread(brain_df.mask_path[i]).max(), cv2.imread(brain_df.mask_path[i]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:52:04.045652Z",
     "iopub.status.busy": "2020-11-17T11:52:04.044250Z",
     "iopub.status.idle": "2020-11-17T11:52:07.311207Z",
     "shell.execute_reply": "2020-11-17T11:52:07.311754Z"
    },
    "papermill": {
     "duration": 3.323546,
     "end_time": "2020-11-17T11:52:07.311895",
     "exception": false,
     "start_time": "2020-11-17T11:52:03.988349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic visualizations: Visualize the images (MRI and Mask) in the dataset separately \n",
    "\n",
    "fig, axs = plt.subplots(6,2, figsize=(16,26))\n",
    "count = 0\n",
    "for x in range(6):\n",
    "  i = random.randint(0, len(brain_df)) # select a random index\n",
    "  axs[count][0].title.set_text(\"Brain MRI\") # set title\n",
    "  axs[count][0].imshow(cv2.imread(brain_df.image_path[i])) # show MRI \n",
    "  axs[count][1].title.set_text(\"Mask - \" + str(brain_df['mask'][i])) # plot title on the mask (0 or 1)\n",
    "  axs[count][1].imshow(cv2.imread(brain_df.mask_path[i])) # Show corresponding mask\n",
    "  count += 1\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:52:07.451908Z",
     "iopub.status.busy": "2020-11-17T11:52:07.450855Z",
     "iopub.status.idle": "2020-11-17T11:52:14.265881Z",
     "shell.execute_reply": "2020-11-17T11:52:14.266455Z"
    },
    "papermill": {
     "duration": 6.893551,
     "end_time": "2020-11-17T11:52:14.266595",
     "exception": false,
     "start_time": "2020-11-17T11:52:07.373044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "i = 0\n",
    "fig,axs = plt.subplots(12,3, figsize=(20,50))\n",
    "for mask in brain_df['mask']:\n",
    "    if (mask==1):\n",
    "        img = io.imread(brain_df.image_path[i])\n",
    "        axs[count][0].title.set_text(\"Brain MRI\")\n",
    "        axs[count][0].imshow(img)\n",
    "        \n",
    "        mask = io.imread(brain_df.mask_path[i])\n",
    "        axs[count][1].title.set_text(\"Mask\")\n",
    "        axs[count][1].imshow(mask, cmap='gray')\n",
    "        \n",
    "        img[mask==255] = (0,255,150)  # change pixel color at the position of mask\n",
    "        axs[count][2].title.set_text(\"MRI with Mask\")\n",
    "        axs[count][2].imshow(img)\n",
    "        count +=1\n",
    "    i += 1\n",
    "    if (count==12):\n",
    "        break\n",
    "        \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.088479,
     "end_time": "2020-11-17T11:52:14.446152",
     "exception": false,
     "start_time": "2020-11-17T11:52:14.357673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5: CRETING TEST, TRAIN & VAL SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:52:14.619117Z",
     "iopub.status.busy": "2020-11-17T11:52:14.618482Z",
     "iopub.status.idle": "2020-11-17T11:52:14.634611Z",
     "shell.execute_reply": "2020-11-17T11:52:14.635299Z"
    },
    "papermill": {
     "duration": 0.105114,
     "end_time": "2020-11-17T11:52:14.635482",
     "exception": false,
     "start_time": "2020-11-17T11:52:14.530368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain_df_train = brain_df.drop(columns=['patient_id'])\n",
    "# Convert the data in mask column to string format, to use categorical mode in flow_from_dataframe\n",
    "brain_df_train['mask'] = brain_df_train['mask'].apply(lambda x: str(x))\n",
    "brain_df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:52:14.808916Z",
     "iopub.status.busy": "2020-11-17T11:52:14.808129Z",
     "iopub.status.idle": "2020-11-17T11:52:14.853988Z",
     "shell.execute_reply": "2020-11-17T11:52:14.853503Z"
    },
    "papermill": {
     "duration": 0.134409,
     "end_time": "2020-11-17T11:52:14.854103",
     "exception": false,
     "start_time": "2020-11-17T11:52:14.719694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(brain_df_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:52:15.049680Z",
     "iopub.status.busy": "2020-11-17T11:52:15.048736Z",
     "iopub.status.idle": "2020-11-17T11:52:16.488621Z",
     "shell.execute_reply": "2020-11-17T11:52:16.487605Z"
    },
    "papermill": {
     "duration": 1.551714,
     "end_time": "2020-11-17T11:52:16.488738",
     "exception": false,
     "start_time": "2020-11-17T11:52:14.937024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255., validation_split=0.1)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(train,\n",
    "                                              directory='./',\n",
    "                                              x_col='image_path',\n",
    "                                              y_col='mask',\n",
    "                                              subset='training',\n",
    "                                              class_mode='categorical',\n",
    "                                              batch_size=16,\n",
    "                                              shuffle=True,\n",
    "                                              target_size=(256,256)\n",
    "                                             )\n",
    "valid_generator = datagen.flow_from_dataframe(train,\n",
    "                                              directory='./',\n",
    "                                              x_col='image_path',\n",
    "                                              y_col='mask',\n",
    "                                              subset='validation',\n",
    "                                              class_mode='categorical',\n",
    "                                              batch_size=16,\n",
    "                                              shuffle=True,\n",
    "                                              target_size=(256,256)\n",
    "                                             )\n",
    "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "test_generator = test_datagen.flow_from_dataframe(test,\n",
    "                                                  directory='./',\n",
    "                                                  x_col='image_path',\n",
    "                                                  y_col='mask',\n",
    "                                                  class_mode='categorical',\n",
    "                                                  batch_size=16,\n",
    "                                                  shuffle=False,\n",
    "                                                  target_size=(256,256)\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.085656,
     "end_time": "2020-11-17T11:52:16.660815",
     "exception": false,
     "start_time": "2020-11-17T11:52:16.575159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6: TRAIN A CLASSIFIER MODEL TO DETECT IF TUMOR EXISTS OR NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-11-17T11:52:16.839592Z",
     "iopub.status.busy": "2020-11-17T11:52:16.838938Z",
     "iopub.status.idle": "2020-11-17T11:52:22.558477Z",
     "shell.execute_reply": "2020-11-17T11:52:22.559314Z"
    },
    "papermill": {
     "duration": 5.812787,
     "end_time": "2020-11-17T11:52:22.559505",
     "exception": false,
     "start_time": "2020-11-17T11:52:16.746718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "clf_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(256,256,3)))\n",
    "clf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:52:22.786427Z",
     "iopub.status.busy": "2020-11-17T11:52:22.784619Z",
     "iopub.status.idle": "2020-11-17T11:52:22.787092Z",
     "shell.execute_reply": "2020-11-17T11:52:22.787572Z"
    },
    "papermill": {
     "duration": 0.098576,
     "end_time": "2020-11-17T11:52:22.787698",
     "exception": false,
     "start_time": "2020-11-17T11:52:22.689122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# before this i tried with trainable layer but the accuracy was less as compared\n",
    "for layer in clf_model.layers:\n",
    "    layers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:52:22.983574Z",
     "iopub.status.busy": "2020-11-17T11:52:22.980931Z",
     "iopub.status.idle": "2020-11-17T11:52:23.158049Z",
     "shell.execute_reply": "2020-11-17T11:52:23.158907Z"
    },
    "papermill": {
     "duration": 0.280476,
     "end_time": "2020-11-17T11:52:23.159109",
     "exception": false,
     "start_time": "2020-11-17T11:52:22.878633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "head = clf_model.output\n",
    "head = AveragePooling2D(pool_size=(4,4))(head)\n",
    "head = Flatten(name='Flatten')(head)\n",
    "head = Dense(256, activation='relu')(head)\n",
    "head = Dropout(0.3)(head)\n",
    "head = Dense(256, activation='relu')(head)\n",
    "head = Dropout(0.3)(head)\n",
    "head = Dense(2, activation='softmax')(head)\n",
    "\n",
    "model = Model(clf_model.input, head)\n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics= [\"accuracy\"]\n",
    "             )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:52:23.426823Z",
     "iopub.status.busy": "2020-11-17T11:52:23.424967Z",
     "iopub.status.idle": "2020-11-17T11:52:23.427493Z",
     "shell.execute_reply": "2020-11-17T11:52:23.427960Z"
    },
    "papermill": {
     "duration": 0.106313,
     "end_time": "2020-11-17T11:52:23.428086",
     "exception": false,
     "start_time": "2020-11-17T11:52:23.321773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(monitor='val_loss', \n",
    "                              mode='min', \n",
    "                              verbose=1, \n",
    "                              patience=15\n",
    "                             )\n",
    "checkpointer = ModelCheckpoint(filepath=\"clf-resnet-weights.hdf5\", \n",
    "                               verbose=1, \n",
    "                               save_best_only=True\n",
    "                              )\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              verbose=1,\n",
    "                              patience=10,\n",
    "                              min_delta=0.0001,\n",
    "                              factor=0.2\n",
    "                             )\n",
    "callbacks = [checkpointer, earlystopping, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T11:52:23.619740Z",
     "iopub.status.busy": "2020-11-17T11:52:23.619068Z",
     "iopub.status.idle": "2020-11-17T12:06:19.500225Z",
     "shell.execute_reply": "2020-11-17T12:06:19.499595Z"
    },
    "papermill": {
     "duration": 835.980325,
     "end_time": "2020-11-17T12:06:19.500385",
     "exception": false,
     "start_time": "2020-11-17T11:52:23.520060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "h = model.fit(train_generator, \n",
    "              steps_per_epoch= train_generator.n // train_generator.batch_size, \n",
    "              epochs = 50, \n",
    "              validation_data= valid_generator, \n",
    "              validation_steps= valid_generator.n // valid_generator.batch_size, \n",
    "              callbacks=[checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:06:24.056667Z",
     "iopub.status.busy": "2020-11-17T12:06:24.055544Z",
     "iopub.status.idle": "2020-11-17T12:06:24.104430Z",
     "shell.execute_reply": "2020-11-17T12:06:24.103866Z"
    },
    "papermill": {
     "duration": 2.448153,
     "end_time": "2020-11-17T12:06:24.104542",
     "exception": false,
     "start_time": "2020-11-17T12:06:21.656389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saving model achitecture in json file\n",
    "model_json = model.to_json()\n",
    "with open(\"clf-resnet-model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.171635,
     "end_time": "2020-11-17T12:06:28.395440",
     "exception": false,
     "start_time": "2020-11-17T12:06:26.223805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7: CLASSIFIACTION MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:06:32.663124Z",
     "iopub.status.busy": "2020-11-17T12:06:32.662193Z",
     "iopub.status.idle": "2020-11-17T12:06:32.665226Z",
     "shell.execute_reply": "2020-11-17T12:06:32.665710Z"
    },
    "papermill": {
     "duration": 2.126741,
     "end_time": "2020-11-17T12:06:32.665832",
     "exception": false,
     "start_time": "2020-11-17T12:06:30.539091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "h.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:06:37.229650Z",
     "iopub.status.busy": "2020-11-17T12:06:37.228587Z",
     "iopub.status.idle": "2020-11-17T12:06:37.560092Z",
     "shell.execute_reply": "2020-11-17T12:06:37.558949Z"
    },
    "papermill": {
     "duration": 2.503202,
     "end_time": "2020-11-17T12:06:37.560225",
     "exception": false,
     "start_time": "2020-11-17T12:06:35.057023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(h.history['loss']);\n",
    "plt.plot(h.history['val_loss']);\n",
    "plt.title(\"Classification Model LOSS\");\n",
    "plt.ylabel(\"loss\");\n",
    "plt.xlabel(\"Epochs\");\n",
    "plt.legend(['train', 'val']);\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(h.history['accuracy']);\n",
    "plt.plot(h.history['val_accuracy']);\n",
    "plt.title(\"Classification Model Acc\");\n",
    "plt.ylabel(\"Accuracy\");\n",
    "plt.xlabel(\"Epochs\");\n",
    "plt.legend(['train', 'val']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:06:41.804870Z",
     "iopub.status.busy": "2020-11-17T12:06:41.803766Z",
     "iopub.status.idle": "2020-11-17T12:06:45.853528Z",
     "shell.execute_reply": "2020-11-17T12:06:45.852021Z"
    },
    "papermill": {
     "duration": 6.178862,
     "end_time": "2020-11-17T12:06:45.853666",
     "exception": false,
     "start_time": "2020-11-17T12:06:39.674804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, acc = model.evaluate(test_generator)\n",
    "print(\"Test accuracy : {} %\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:06:50.166983Z",
     "iopub.status.busy": "2020-11-17T12:06:50.165391Z",
     "iopub.status.idle": "2020-11-17T12:06:52.786473Z",
     "shell.execute_reply": "2020-11-17T12:06:52.785893Z"
    },
    "papermill": {
     "duration": 4.807441,
     "end_time": "2020-11-17T12:06:52.786634",
     "exception": false,
     "start_time": "2020-11-17T12:06:47.979193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(test_generator)\n",
    "\n",
    "pred = np.argmax(prediction, axis=1)\n",
    "#pred = np.asarray(pred).astype('str')\n",
    "original = np.asarray(test['mask']).astype('int')\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "accuracy = accuracy_score(original, pred)\n",
    "print(accuracy)\n",
    "\n",
    "cm = confusion_matrix(original, pred)\n",
    "\n",
    "report = classification_report(original, pred, labels = [0,1])\n",
    "print(report)\n",
    "plt.figure(figsize = (5,5))\n",
    "sns.heatmap(cm, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.35256,
     "end_time": "2020-11-17T12:06:57.271539",
     "exception": false,
     "start_time": "2020-11-17T12:06:54.918979",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8: BUILDING A SEGMENTATION MODEL TO LOCALIZE TUMOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:07:01.627494Z",
     "iopub.status.busy": "2020-11-17T12:07:01.626824Z",
     "iopub.status.idle": "2020-11-17T12:07:01.632307Z",
     "shell.execute_reply": "2020-11-17T12:07:01.631783Z"
    },
    "papermill": {
     "duration": 2.224595,
     "end_time": "2020-11-17T12:07:01.632413",
     "exception": false,
     "start_time": "2020-11-17T12:06:59.407818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain_df_mask = brain_df[brain_df['mask'] == 1]\n",
    "brain_df_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:07:05.923045Z",
     "iopub.status.busy": "2020-11-17T12:07:05.922081Z",
     "iopub.status.idle": "2020-11-17T12:07:05.930470Z",
     "shell.execute_reply": "2020-11-17T12:07:05.929946Z"
    },
    "papermill": {
     "duration": 2.15075,
     "end_time": "2020-11-17T12:07:05.930592",
     "exception": false,
     "start_time": "2020-11-17T12:07:03.779842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating test, train and val sets\n",
    "X_train, X_val = train_test_split(brain_df_mask, test_size=0.15)\n",
    "X_test, X_val = train_test_split(X_val, test_size=0.5)\n",
    "print(\"Train size is {}, valid size is {} & test size is {}\".format(len(X_train), len(X_val), len(X_test)))\n",
    "\n",
    "train_ids = list(X_train.image_path)\n",
    "train_mask = list(X_train.mask_path)\n",
    "\n",
    "val_ids = list(X_val.image_path)\n",
    "val_mask= list(X_val.mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:07:10.744180Z",
     "iopub.status.busy": "2020-11-17T12:07:10.743230Z",
     "iopub.status.idle": "2020-11-17T12:07:10.767570Z",
     "shell.execute_reply": "2020-11-17T12:07:10.768714Z"
    },
    "papermill": {
     "duration": 2.428553,
     "end_time": "2020-11-17T12:07:10.768897",
     "exception": false,
     "start_time": "2020-11-17T12:07:08.340344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "  def __init__(self, ids , mask, image_dir = './', batch_size = 16, img_h = 256, img_w = 256, shuffle = True):\n",
    "\n",
    "    self.ids = ids\n",
    "    self.mask = mask\n",
    "    self.image_dir = image_dir\n",
    "    self.batch_size = batch_size\n",
    "    self.img_h = img_h\n",
    "    self.img_w = img_w\n",
    "    self.shuffle = shuffle\n",
    "    self.on_epoch_end()\n",
    "\n",
    "  def __len__(self):\n",
    "    'Get the number of batches per epoch'\n",
    "\n",
    "    return int(np.floor(len(self.ids)) / self.batch_size)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    'Generate a batch of data'\n",
    "\n",
    "    #generate index of batch_size length\n",
    "    indexes = self.indexes[index* self.batch_size : (index+1) * self.batch_size]\n",
    "\n",
    "    #get the ImageId corresponding to the indexes created above based on batch size\n",
    "    list_ids = [self.ids[i] for i in indexes]\n",
    "\n",
    "    #get the MaskId corresponding to the indexes created above based on batch size\n",
    "    list_mask = [self.mask[i] for i in indexes]\n",
    "\n",
    "\n",
    "    #generate data for the X(features) and y(label)\n",
    "    X, y = self.__data_generation(list_ids, list_mask)\n",
    "\n",
    "    #returning the data\n",
    "    return X, y\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    'Used for updating the indices after each epoch, once at the beginning as well as at the end of each epoch'\n",
    "    \n",
    "    #getting the array of indices based on the input dataframe\n",
    "    self.indexes = np.arange(len(self.ids))\n",
    "\n",
    "    #if shuffle is true, shuffle the indices\n",
    "    if self.shuffle:\n",
    "      np.random.shuffle(self.indexes)\n",
    "\n",
    "  def __data_generation(self, list_ids, list_mask):\n",
    "    'generate the data corresponding the indexes in a given batch of images'\n",
    "\n",
    "    # create empty arrays of shape (batch_size,height,width,depth) \n",
    "    #Depth is 3 for input and depth is taken as 1 for output becasue mask consist only of 1 channel.\n",
    "    X = np.empty((self.batch_size, self.img_h, self.img_w, 3))\n",
    "    y = np.empty((self.batch_size, self.img_h, self.img_w, 1))\n",
    "\n",
    "    #iterate through the dataframe rows, whose size is equal to the batch_size\n",
    "    for i in range(len(list_ids)):\n",
    "      #path of the image\n",
    "      img_path = str(list_ids[i])\n",
    "      \n",
    "      #mask path\n",
    "      mask_path = str(list_mask[i])\n",
    "      \n",
    "      #reading the original image and the corresponding mask image\n",
    "      img = io.imread(img_path)\n",
    "      mask = io.imread(mask_path)\n",
    "\n",
    "      #resizing and coverting them to array of type float64\n",
    "      img = cv2.resize(img,(self.img_h,self.img_w))\n",
    "      img = np.array(img, dtype = np.float64)\n",
    "      \n",
    "      mask = cv2.resize(mask,(self.img_h,self.img_w))\n",
    "      mask = np.array(mask, dtype = np.float64)\n",
    "\n",
    "      #standardising \n",
    "      img -= img.mean()\n",
    "      img /= img.std()\n",
    "      \n",
    "      mask -= mask.mean()\n",
    "      mask /= mask.std()\n",
    "      \n",
    "      #Adding image to the empty array\n",
    "      X[i,] = img\n",
    "      \n",
    "      #expanding the dimnesion of the image from (256,256) to (256,256,1)\n",
    "      y[i,] = np.expand_dims(mask, axis = 2)\n",
    "    \n",
    "    #normalizing y\n",
    "    y = (y > 0).astype(int)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "train_data = DataGenerator(train_ids, train_mask)\n",
    "val_data = DataGenerator(val_ids, val_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.233907,
     "end_time": "2020-11-17T12:07:15.271507",
     "exception": false,
     "start_time": "2020-11-17T12:07:13.037600",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![alt text](https://drive.google.com/uc?id=1WOmTUGT_3oN_ltzWlq9ofsw9E1eJwfwH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.224755,
     "end_time": "2020-11-17T12:07:20.600389",
     "exception": false,
     "start_time": "2020-11-17T12:07:18.375634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![alt text](https://drive.google.com/uc?id=10XpINWmLDApPhIjxq_o8aTbeRjXIQRTD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:07:24.924466Z",
     "iopub.status.busy": "2020-11-17T12:07:24.923736Z",
     "iopub.status.idle": "2020-11-17T12:07:24.928166Z",
     "shell.execute_reply": "2020-11-17T12:07:24.927664Z"
    },
    "papermill": {
     "duration": 2.1505,
     "end_time": "2020-11-17T12:07:24.928284",
     "exception": false,
     "start_time": "2020-11-17T12:07:22.777784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lets create model now\n",
    "def resblock(X, f):\n",
    "    '''\n",
    "    function for creating res block\n",
    "    '''\n",
    "    X_copy = X  #copy of input\n",
    "    \n",
    "    # main path\n",
    "    X = Conv2D(f, kernel_size=(1,1), kernel_initializer='he_normal')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(f, kernel_size=(3,3), padding='same', kernel_initializer='he_normal')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    # shortcut path\n",
    "    X_copy = Conv2D(f, kernel_size=(1,1), kernel_initializer='he_normal')(X_copy)\n",
    "    X_copy = BatchNormalization()(X_copy)\n",
    "    \n",
    "    # Adding the output from main path and short path together\n",
    "    X = Add()([X, X_copy])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def upsample_concat(x, skip):\n",
    "    '''\n",
    "    funtion for upsampling image\n",
    "    '''\n",
    "    X = UpSampling2D((2,2))(x)\n",
    "    merge = Concatenate()([X, skip])\n",
    "    \n",
    "    return merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:07:29.465539Z",
     "iopub.status.busy": "2020-11-17T12:07:29.464852Z",
     "iopub.status.idle": "2020-11-17T12:07:30.314815Z",
     "shell.execute_reply": "2020-11-17T12:07:30.313639Z"
    },
    "papermill": {
     "duration": 3.259451,
     "end_time": "2020-11-17T12:07:30.314981",
     "exception": false,
     "start_time": "2020-11-17T12:07:27.055530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_shape = (256,256,3)\n",
    "X_input = Input(input_shape) #iniating tensor of input shape\n",
    "\n",
    "# Stage 1\n",
    "conv_1 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(X_input)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "conv_1 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv_1)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "pool_1 = MaxPool2D((2,2))(conv_1)\n",
    "\n",
    "# stage 2\n",
    "conv_2 = resblock(pool_1, 32)\n",
    "pool_2 = MaxPool2D((2,2))(conv_2)\n",
    "\n",
    "# Stage 3\n",
    "conv_3 = resblock(pool_2, 64)\n",
    "pool_3 = MaxPool2D((2,2))(conv_3)\n",
    "\n",
    "# Stage 4\n",
    "conv_4 = resblock(pool_3, 128)\n",
    "pool_4 = MaxPool2D((2,2))(conv_4)\n",
    "\n",
    "# Stage 5 (bottle neck)\n",
    "conv_5 = resblock(pool_4, 256)\n",
    "\n",
    "# Upsample Stage 1\n",
    "up_1 = upsample_concat(conv_5, conv_4)\n",
    "up_1 = resblock(up_1, 128)\n",
    "\n",
    "# Upsample Stage 2\n",
    "up_2 = upsample_concat(up_1, conv_3)\n",
    "up_2 = resblock(up_2, 64)\n",
    "\n",
    "# Upsample Stage 3\n",
    "up_3 = upsample_concat(up_2, conv_2)\n",
    "up_3 = resblock(up_3, 32)\n",
    "\n",
    "# Upsample Stage 4\n",
    "up_4 = upsample_concat(up_3, conv_1)\n",
    "up_4 = resblock(up_4, 16)\n",
    "\n",
    "# final output\n",
    "out = Conv2D(1, (1,1), kernel_initializer='he_normal', padding='same', activation='sigmoid')(up_4)\n",
    "\n",
    "seg_model = Model(X_input, out)\n",
    "seg_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.166116,
     "end_time": "2020-11-17T12:07:34.657118",
     "exception": false,
     "start_time": "2020-11-17T12:07:32.491002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 9: TRAINING SEGMENTATION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:07:38.969170Z",
     "iopub.status.busy": "2020-11-17T12:07:38.968328Z",
     "iopub.status.idle": "2020-11-17T12:07:39.021308Z",
     "shell.execute_reply": "2020-11-17T12:07:39.020731Z"
    },
    "papermill": {
     "duration": 2.231821,
     "end_time": "2020-11-17T12:07:39.021423",
     "exception": false,
     "start_time": "2020-11-17T12:07:36.789602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "epsilon = 1e-5\n",
    "smooth = 1\n",
    "\n",
    "def tversky(y_true, y_pred):\n",
    "    y_true_pos = K.flatten(y_true)\n",
    "    y_pred_pos = K.flatten(y_pred)\n",
    "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
    "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
    "    alpha = 0.7\n",
    "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
    "\n",
    "def focal_tversky(y_true,y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    pt_1 = tversky(y_true, y_pred)\n",
    "    gamma = 0.75\n",
    "    return K.pow((1-pt_1), gamma)\n",
    "\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    return 1 - tversky(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:07:43.590886Z",
     "iopub.status.busy": "2020-11-17T12:07:43.589883Z",
     "iopub.status.idle": "2020-11-17T12:07:43.598209Z",
     "shell.execute_reply": "2020-11-17T12:07:43.597714Z"
    },
    "papermill": {
     "duration": 2.168629,
     "end_time": "2020-11-17T12:07:43.598365",
     "exception": false,
     "start_time": "2020-11-17T12:07:41.429736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compling model and callbacks functions\n",
    "adam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\n",
    "seg_model.compile(optimizer = adam, \n",
    "                  loss = focal_tversky, \n",
    "                  metrics = [tversky]\n",
    "                 )\n",
    "#callbacks\n",
    "earlystopping = EarlyStopping(monitor='val_loss',\n",
    "                              mode='min', \n",
    "                              verbose=1, \n",
    "                              patience=20\n",
    "                             )\n",
    "# save the best model with lower validation loss\n",
    "checkpointer = ModelCheckpoint(filepath=\"ResUNet-segModel-weights.hdf5\", \n",
    "                               verbose=1, \n",
    "                               save_best_only=True\n",
    "                              )\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              verbose=1,\n",
    "                              patience=10,\n",
    "                              min_delta=0.0001,\n",
    "                              factor=0.2\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:07:47.942123Z",
     "iopub.status.busy": "2020-11-17T12:07:47.941348Z",
     "iopub.status.idle": "2020-11-17T12:15:56.146124Z",
     "shell.execute_reply": "2020-11-17T12:15:56.146792Z"
    },
    "papermill": {
     "duration": 490.360983,
     "end_time": "2020-11-17T12:15:56.146990",
     "exception": false,
     "start_time": "2020-11-17T12:07:45.786007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "h = seg_model.fit(train_data, \n",
    "                  epochs = 60, \n",
    "                  validation_data = val_data,\n",
    "                  callbacks = [checkpointer, earlystopping, reduce_lr]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:16:03.143214Z",
     "iopub.status.busy": "2020-11-17T12:16:03.135297Z",
     "iopub.status.idle": "2020-11-17T12:16:03.165585Z",
     "shell.execute_reply": "2020-11-17T12:16:03.165031Z"
    },
    "papermill": {
     "duration": 3.547437,
     "end_time": "2020-11-17T12:16:03.165695",
     "exception": false,
     "start_time": "2020-11-17T12:15:59.618258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saving model achitecture in json file\n",
    "seg_model_json = seg_model.to_json()\n",
    "with open(\"ResUNet-seg-model.json\", \"w\") as json_file:\n",
    "    json_file.write(seg_model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 3.643986,
     "end_time": "2020-11-17T12:16:10.575526",
     "exception": false,
     "start_time": "2020-11-17T12:16:06.931540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 10: SEGMENTATION MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:16:18.327758Z",
     "iopub.status.busy": "2020-11-17T12:16:18.325823Z",
     "iopub.status.idle": "2020-11-17T12:16:18.330079Z",
     "shell.execute_reply": "2020-11-17T12:16:18.329568Z"
    },
    "papermill": {
     "duration": 4.036401,
     "end_time": "2020-11-17T12:16:18.330183",
     "exception": false,
     "start_time": "2020-11-17T12:16:14.293782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "h.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:16:25.800725Z",
     "iopub.status.busy": "2020-11-17T12:16:25.799821Z",
     "iopub.status.idle": "2020-11-17T12:16:26.109142Z",
     "shell.execute_reply": "2020-11-17T12:16:26.109642Z"
    },
    "papermill": {
     "duration": 4.186616,
     "end_time": "2020-11-17T12:16:26.109774",
     "exception": false,
     "start_time": "2020-11-17T12:16:21.923158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(h.history['loss']);\n",
    "plt.plot(h.history['val_loss']);\n",
    "plt.title(\"SEG Model focal tversky Loss\");\n",
    "plt.ylabel(\"focal tversky loss\");\n",
    "plt.xlabel(\"Epochs\");\n",
    "plt.legend(['train', 'val']);\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(h.history['tversky']);\n",
    "plt.plot(h.history['val_tversky']);\n",
    "plt.title(\"SEG Model tversky score\");\n",
    "plt.ylabel(\"tversky Accuracy\");\n",
    "plt.xlabel(\"Epochs\");\n",
    "plt.legend(['train', 'val']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:16:33.401359Z",
     "iopub.status.busy": "2020-11-17T12:16:33.400694Z",
     "iopub.status.idle": "2020-11-17T12:16:34.048846Z",
     "shell.execute_reply": "2020-11-17T12:16:34.048083Z"
    },
    "papermill": {
     "duration": 4.199078,
     "end_time": "2020-11-17T12:16:34.048957",
     "exception": false,
     "start_time": "2020-11-17T12:16:29.849879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ids = list(X_test.image_path)\n",
    "test_mask = list(X_test.mask_path)\n",
    "test_data = DataGenerator(test_ids, test_mask)\n",
    "_, tv = seg_model.evaluate(test_data)\n",
    "print(\"Segmentation tversky is {:.2f}%\".format(tv*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 3.828542,
     "end_time": "2020-11-17T12:16:41.379125",
     "exception": false,
     "start_time": "2020-11-17T12:16:37.550583",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 11: SEGMENTATION MODEL PREFORMACE \n",
    "## (COMBINING CLASSIFICATION AND SEGMENTAION MODEL BUILDING PIPELINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:16:48.488899Z",
     "iopub.status.busy": "2020-11-17T12:16:48.488075Z",
     "iopub.status.idle": "2020-11-17T12:16:48.491977Z",
     "shell.execute_reply": "2020-11-17T12:16:48.491507Z"
    },
    "papermill": {
     "duration": 3.583934,
     "end_time": "2020-11-17T12:16:48.492088",
     "exception": false,
     "start_time": "2020-11-17T12:16:44.908154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction(test, model, model_seg):\n",
    "    '''\n",
    "    Predcition function which takes dataframe containing ImageID as Input and perform 2 type of prediction on the image\n",
    "    Initially, image is passed through the classification network which predicts whether the image has defect or not, if the model\n",
    "    is 99% sure that the image has no defect, then the image is labeled as no-defect, if the model is not sure, it passes the image to the\n",
    "    segmentation network, it again checks if the image has defect or not, if it has defect, then the type and location of defect is found\n",
    "    '''\n",
    "    # empty list to store results\n",
    "    mask, image_id, has_mask = [], [], []\n",
    "    \n",
    "    #itetrating through each image in test data\n",
    "    for i in test.image_path:\n",
    "        \n",
    "        img = io.imread(i)\n",
    "        #normalizing\n",
    "        img = img *1./255.\n",
    "        #reshaping\n",
    "        img = cv2.resize(img, (256,256))\n",
    "        # converting img into array\n",
    "        img = np.array(img, dtype=np.float64)\n",
    "        #reshaping the image from 256,256,3 to 1,256,256,3\n",
    "        img = np.reshape(img, (1,256,256,3))\n",
    "        \n",
    "        #making prediction for tumor in image\n",
    "        is_defect = model.predict(img)\n",
    "        \n",
    "        #if tumour is not present we append the details of the image to the list\n",
    "        if np.argmax(is_defect)==0:\n",
    "            image_id.append(i)\n",
    "            has_mask.append(0)\n",
    "            mask.append('No mask :)')\n",
    "            continue\n",
    "        \n",
    "        #Creating a empty array of shape 1,256,256,1\n",
    "        X = np.empty((1,256,256,3))\n",
    "        # read the image\n",
    "        img = io.imread(i)\n",
    "        #resizing the image and coverting them to array of type float64\n",
    "        img = cv2.resize(img, (256,256))\n",
    "        img = np.array(img, dtype=np.float64)\n",
    "        \n",
    "        # standardising the image\n",
    "        img -= img.mean()\n",
    "        img /= img.std()\n",
    "        #converting the shape of image from 256,256,3 to 1,256,256,3\n",
    "        X[0,] = img\n",
    "        \n",
    "        #make prediction of mask\n",
    "        predict = model_seg.predict(X)\n",
    "        \n",
    "        # if sum of predicted mask is 0 then there is not tumour\n",
    "        if predict.round().astype(int).sum()==0:\n",
    "            image_id.append(i)\n",
    "            has_mask.append(0)\n",
    "            mask.append('No mask :)')\n",
    "        else:\n",
    "        #if the sum of pixel values are more than 0, then there is tumour\n",
    "            image_id.append(i)\n",
    "            has_mask.append(1)\n",
    "            mask.append(predict)\n",
    "            \n",
    "    return pd.DataFrame({'image_path': image_id,'predicted_mask': mask,'has_mask': has_mask})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:16:56.085264Z",
     "iopub.status.busy": "2020-11-17T12:16:56.084380Z",
     "iopub.status.idle": "2020-11-17T12:17:41.922017Z",
     "shell.execute_reply": "2020-11-17T12:17:41.922961Z"
    },
    "papermill": {
     "duration": 49.737654,
     "end_time": "2020-11-17T12:17:41.923170",
     "exception": false,
     "start_time": "2020-11-17T12:16:52.185516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# making prediction\n",
    "df_pred = prediction(test, model, seg_model)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:17:49.183866Z",
     "iopub.status.busy": "2020-11-17T12:17:49.183222Z",
     "iopub.status.idle": "2020-11-17T12:17:55.687836Z",
     "shell.execute_reply": "2020-11-17T12:17:55.687047Z"
    },
    "papermill": {
     "duration": 10.034001,
     "end_time": "2020-11-17T12:17:55.687945",
     "exception": false,
     "start_time": "2020-11-17T12:17:45.653944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merging original and prediction df\n",
    "df_pred = test.merge(df_pred, on='image_path')\n",
    "df_pred.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T12:18:03.278412Z",
     "iopub.status.busy": "2020-11-17T12:18:03.277475Z",
     "iopub.status.idle": "2020-11-17T12:18:16.979218Z",
     "shell.execute_reply": "2020-11-17T12:18:16.979722Z"
    },
    "papermill": {
     "duration": 17.485029,
     "end_time": "2020-11-17T12:18:16.979860",
     "exception": false,
     "start_time": "2020-11-17T12:17:59.494831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#visualizing prediction\n",
    "count = 0\n",
    "fig, axs = plt.subplots(15,5, figsize=(30,70))\n",
    "\n",
    "for i in range(len(df_pred)):\n",
    "    if df_pred.has_mask[i]==1 and count<15:\n",
    "        #read mri images\n",
    "        img = io.imread(df_pred.image_path[i])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        axs[count][0].imshow(img)\n",
    "        axs[count][0].title.set_text('Brain MRI')\n",
    "        \n",
    "        #read original mask\n",
    "        mask = io.imread(df_pred.mask_path[i])\n",
    "        axs[count][1].imshow(mask)\n",
    "        axs[count][1].title.set_text('Original Mask')\n",
    "        \n",
    "        #read predicted mask\n",
    "        pred = np.array(df_pred.predicted_mask[i]).squeeze().round()\n",
    "        axs[count][2].imshow(pred)\n",
    "        axs[count][2].title.set_text('AI predicted mask')\n",
    "        \n",
    "        #overlay original mask with MRI\n",
    "        img[mask==255] = (255,0,0)\n",
    "        axs[count][3].imshow(img)\n",
    "        axs[count][3].title.set_text('Brain MRI with original mask (Ground Truth)')\n",
    "        \n",
    "        #overlay predicted mask and MRI\n",
    "        img_ = io.imread(df_pred.image_path[i])\n",
    "        img_ = cv2.cvtColor(img_, cv2.COLOR_BGR2RGB)\n",
    "        img_[pred==1] = (0,255,150)\n",
    "        axs[count][4].imshow(img_)\n",
    "        axs[count][4].title.set_text('MRI with AI PREDICTED MASK')\n",
    "        \n",
    "        count +=1\n",
    "    if (count==15):\n",
    "        break\n",
    "\n",
    "fig.tight_layout()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 3.620301,
     "end_time": "2020-11-17T12:18:24.543569",
     "exception": false,
     "start_time": "2020-11-17T12:18:20.923268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "the predictions made by AI are almost correct :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "duration": 1616.960272,
   "end_time": "2020-11-17T12:18:30.093737",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-17T11:51:33.133465",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
