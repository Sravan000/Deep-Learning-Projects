{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' defining some useful funcion '''\n",
    "\n",
    "def loading_data(train=40000, test=10000, full=False):\n",
    "    ''' reading data '''\n",
    "    if full:\n",
    "        s_df = pd.read_csv('sudoku.csv').values\n",
    "    else:\n",
    "        ''' converting s_df into array '''\n",
    "        s_df = next(\n",
    "            pd.read_csv('sudoku.csv', chunksize=(train + test))).values\n",
    "        \n",
    "    ''' transposing data '''\n",
    "    q, sols = s_df.T\n",
    "    X = np.array([np.reshape([int(d) for d in flatten_grid], (9, 9)) for flatten_grid in q])\n",
    "    y = np.array([np.reshape([int(d) for d in flatten_grid], (9, 9)) for flatten_grid in sols])\n",
    "    \n",
    "    return (X[:train], y[:train]), (X[train:], y[train:])\n",
    "\n",
    "\n",
    "def diff(grids_true, grids_pred):\n",
    "    \"\"\" This function shows how well predicted quizzes fit to actual solutions. \"\"\"\n",
    "    return (grids_true != grids_pred).sum((1, 2))\n",
    "\n",
    "\n",
    "def del_digits(X, delete=1):\n",
    "    \"\"\" This function is used to create sudoku quizzes from solutions \"\"\"\n",
    "    grids = X.argmax(3)  # get the grid in a (9, 9) integer shape\n",
    "    for grid in grids:\n",
    "        grid.flat[np.random.randint(0, 81, delete)] = 0  # generate blanks (replace = True)\n",
    "        \n",
    "    return to_categorical(grids)\n",
    "\n",
    "\n",
    "def batch_smart_solve(grids, solver):\n",
    "    \"\"\" This function is ugly, feel free to optimize the code \"\"\"\n",
    "    grids = grids.copy()\n",
    "    for _ in range((grids == 0).sum((1, 2)).max()):\n",
    "        pred = np.array(solver.predict(to_categorical(grids)))  # get predictions\n",
    "        probs = pred.max(2).T  # get highest probability for each 81 digit to predict\n",
    "        values = pred.argmax(2).T + 1  # get corresponding values\n",
    "        zeros = (grids == 0).reshape((grids.shape[0], 81))  # get blank positions\n",
    "\n",
    "        for grid, prob, value, zero in zip(grids, probs, values, zeros):\n",
    "            '''  don't try to fill already completed grid'''\n",
    "            if any(zero):  \n",
    "                '''focus on blanks only'''\n",
    "                where = np.where(zero)[0]  \n",
    "                ''' best score FOR A ZERO VALUE (confident blank) '''\n",
    "                conf_pos = where[prob[zero].argmax()] \n",
    "                ''' get corresponding value '''\n",
    "                conf_val = value[conf_pos]  \n",
    "                ''' fill digit inplace '''\n",
    "                grid.flat[conf_pos] = conf_val  \n",
    "    return grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_shape = (9, 9, 10)\n",
    "(_, y_train), (X_test, y_test) = loading_data() \n",
    "\n",
    "''' one-hot encoding'''\n",
    "X_train = to_categorical(y_train).astype('float32')\n",
    "X_test = to_categorical(y_test).astype('float32')\n",
    "\n",
    "y_train = to_categorical(y_train-1).astype('float32') \n",
    "y_test = to_categorical(y_test-1).astype('float32')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Model '''\n",
    "\n",
    "''' container '''\n",
    "model = Sequential()\n",
    "\n",
    "''' 1st Hidden Layer '''\n",
    "model.add(Dense(64, activation='relu', input_shape=inp_shape))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "''' 2nd Hidden Layer '''\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "''' flattening output '''\n",
    "model.add(Flatten())\n",
    "\n",
    "''' Input layer '''\n",
    "inp = Input(shape=inp_shape)  \n",
    "features = model(inp)  # commons features\n",
    "\n",
    "''' Classification Layer '''\n",
    "out = [Dense(9, activation='softmax')(features) for i in range(81)]\n",
    "\n",
    "''' final model '''\n",
    "model = Model(inp, out)  \n",
    "\n",
    "''' compile the model '''\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 213s 470ms/step - loss: 98.4436 - dense_2_loss: 1.2099 - dense_3_loss: 1.2194 - dense_4_loss: 1.2170 - dense_5_loss: 1.2096 - dense_6_loss: 1.2134 - dense_7_loss: 1.2179 - dense_8_loss: 1.2136 - dense_9_loss: 1.2145 - dense_10_loss: 1.2119 - dense_11_loss: 1.2205 - dense_12_loss: 1.2197 - dense_13_loss: 1.2121 - dense_14_loss: 1.2178 - dense_15_loss: 1.2128 - dense_16_loss: 1.2247 - dense_17_loss: 1.2156 - dense_18_loss: 1.2067 - dense_19_loss: 1.2173 - dense_20_loss: 1.2240 - dense_21_loss: 1.2165 - dense_22_loss: 1.2140 - dense_23_loss: 1.2187 - dense_24_loss: 1.2154 - dense_25_loss: 1.2137 - dense_26_loss: 1.2240 - dense_27_loss: 1.2152 - dense_28_loss: 1.2143 - dense_29_loss: 1.2220 - dense_30_loss: 1.2151 - dense_31_loss: 1.2224 - dense_32_loss: 1.2155 - dense_33_loss: 1.2105 - dense_34_loss: 1.2134 - dense_35_loss: 1.2178 - dense_36_loss: 1.2125 - dense_37_loss: 1.2132 - dense_38_loss: 1.2205 - dense_39_loss: 1.2081 - dense_40_loss: 1.2263 - dense_41_loss: 1.2117 - dense_42_loss: 1.2157 - dense_43_loss: 1.2092 - dense_44_loss: 1.2103 - dense_45_loss: 1.2153 - dense_46_loss: 1.2121 - dense_47_loss: 1.2103 - dense_48_loss: 1.2165 - dense_49_loss: 1.2118 - dense_50_loss: 1.2161 - dense_51_loss: 1.2199 - dense_52_loss: 1.2196 - dense_53_loss: 1.2184 - dense_54_loss: 1.2142 - dense_55_loss: 1.2164 - dense_56_loss: 1.2200 - dense_57_loss: 1.2186 - dense_58_loss: 1.2145 - dense_59_loss: 1.2122 - dense_60_loss: 1.2135 - dense_61_loss: 1.2218 - dense_62_loss: 1.2131 - dense_63_loss: 1.2136 - dense_64_loss: 1.2091 - dense_65_loss: 1.2050 - dense_66_loss: 1.2073 - dense_67_loss: 1.2179 - dense_68_loss: 1.2133 - dense_69_loss: 1.2086 - dense_70_loss: 1.2077 - dense_71_loss: 1.2150 - dense_72_loss: 1.2156 - dense_73_loss: 1.2124 - dense_74_loss: 1.2076 - dense_75_loss: 1.2149 - dense_76_loss: 1.2256 - dense_77_loss: 1.2214 - dense_78_loss: 1.2144 - dense_79_loss: 1.2186 - dense_80_loss: 1.2194 - dense_81_loss: 1.2146 - dense_82_loss: 1.2228 - dense_2_accuracy: 0.5975 - dense_3_accuracy: 0.5908 - dense_4_accuracy: 0.5924 - dense_5_accuracy: 0.5991 - dense_6_accuracy: 0.5947 - dense_7_accuracy: 0.5882 - dense_8_accuracy: 0.5948 - dense_9_accuracy: 0.5980 - dense_10_accuracy: 0.5955 - dense_11_accuracy: 0.5889 - dense_12_accuracy: 0.5873 - dense_13_accuracy: 0.5974 - dense_14_accuracy: 0.5888 - dense_15_accuracy: 0.5953 - dense_16_accuracy: 0.5895 - dense_17_accuracy: 0.5927 - dense_18_accuracy: 0.5981 - dense_19_accuracy: 0.5959 - dense_20_accuracy: 0.5857 - dense_21_accuracy: 0.5933 - dense_22_accuracy: 0.5933 - dense_23_accuracy: 0.5953 - dense_24_accuracy: 0.5922 - dense_25_accuracy: 0.5961 - dense_26_accuracy: 0.5844 - dense_27_accuracy: 0.5945 - dense_28_accuracy: 0.5958 - dense_29_accuracy: 0.5889 - dense_30_accuracy: 0.6014 - dense_31_accuracy: 0.5953 - dense_32_accuracy: 0.5920 - dense_33_accuracy: 0.5984 - dense_34_accuracy: 0.5980 - dense_35_accuracy: 0.5892 - dense_36_accuracy: 0.5988 - dense_37_accuracy: 0.5949 - dense_38_accuracy: 0.5952 - dense_39_accuracy: 0.6048 - dense_40_accuracy: 0.5853 - dense_41_accuracy: 0.5951 - dense_42_accuracy: 0.5916 - dense_43_accuracy: 0.5940 - dense_44_accuracy: 0.6001 - dense_45_accuracy: 0.5964 - dense_46_accuracy: 0.6011 - dense_47_accuracy: 0.5973 - dense_48_accuracy: 0.5982 - dense_49_accuracy: 0.5910 - dense_50_accuracy: 0.5964 - dense_51_accuracy: 0.5896 - dense_52_accuracy: 0.5920 - dense_53_accuracy: 0.5895 - dense_54_accuracy: 0.5946 - dense_55_accuracy: 0.5945 - dense_56_accuracy: 0.5949 - dense_57_accuracy: 0.5875 - dense_58_accuracy: 0.5955 - dense_59_accuracy: 0.5975 - dense_60_accuracy: 0.5952 - dense_61_accuracy: 0.5861 - dense_62_accuracy: 0.5972 - dense_63_accuracy: 0.5922 - dense_64_accuracy: 0.5954 - dense_65_accuracy: 0.6056 - dense_66_accuracy: 0.5997 - dense_67_accuracy: 0.5914 - dense_68_accuracy: 0.5980 - dense_69_accuracy: 0.5970 - dense_70_accuracy: 0.6008 - dense_71_accuracy: 0.5927 - dense_72_accuracy: 0.5964 - dense_73_accuracy: 0.6016 - dense_74_accuracy: 0.5986 - dense_75_accuracy: 0.5954 - dense_76_accuracy: 0.5851 - dense_77_accuracy: 0.5896 - dense_78_accuracy: 0.5974 - dense_79_accuracy: 0.5968 - dense_80_accuracy: 0.5926 - dense_81_accuracy: 0.5935 - dense_82_accuracy: 0.5890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x270c5d03640>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' training '''\n",
    "model.fit(del_digits(X_train, 0), [y_train[:, i, j, :] for i in range(9) for j in range(9)], batch_size=128, epochs=1, \n",
    "           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass nÂ° 1 ...\n",
      "313/313 [==============================] - 271s 679ms/step - loss: 101.4047 - dense_85_loss: 1.2509 - dense_86_loss: 1.2499 - dense_87_loss: 1.2527 - dense_88_loss: 1.2504 - dense_89_loss: 1.2519 - dense_90_loss: 1.2501 - dense_91_loss: 1.2526 - dense_92_loss: 1.2511 - dense_93_loss: 1.2454 - dense_94_loss: 1.2581 - dense_95_loss: 1.2569 - dense_96_loss: 1.2457 - dense_97_loss: 1.2512 - dense_98_loss: 1.2487 - dense_99_loss: 1.2562 - dense_100_loss: 1.2479 - dense_101_loss: 1.2514 - dense_102_loss: 1.2525 - dense_103_loss: 1.2511 - dense_104_loss: 1.2439 - dense_105_loss: 1.2549 - dense_106_loss: 1.2519 - dense_107_loss: 1.2438 - dense_108_loss: 1.2527 - dense_109_loss: 1.2525 - dense_110_loss: 1.2527 - dense_111_loss: 1.2572 - dense_112_loss: 1.2491 - dense_113_loss: 1.2561 - dense_114_loss: 1.2550 - dense_115_loss: 1.2580 - dense_116_loss: 1.2499 - dense_117_loss: 1.2531 - dense_118_loss: 1.2577 - dense_119_loss: 1.2493 - dense_120_loss: 1.2508 - dense_121_loss: 1.2598 - dense_122_loss: 1.2396 - dense_123_loss: 1.2455 - dense_124_loss: 1.2568 - dense_125_loss: 1.2575 - dense_126_loss: 1.2620 - dense_127_loss: 1.2425 - dense_128_loss: 1.2440 - dense_129_loss: 1.2535 - dense_130_loss: 1.2562 - dense_131_loss: 1.2611 - dense_132_loss: 1.2407 - dense_133_loss: 1.2554 - dense_134_loss: 1.2455 - dense_135_loss: 1.2404 - dense_136_loss: 1.2454 - dense_137_loss: 1.2502 - dense_138_loss: 1.2501 - dense_139_loss: 1.2586 - dense_140_loss: 1.2525 - dense_141_loss: 1.2568 - dense_142_loss: 1.2430 - dense_143_loss: 1.2465 - dense_144_loss: 1.2578 - dense_145_loss: 1.2581 - dense_146_loss: 1.2549 - dense_147_loss: 1.2685 - dense_148_loss: 1.2455 - dense_149_loss: 1.2542 - dense_150_loss: 1.2586 - dense_151_loss: 1.2523 - dense_152_loss: 1.2497 - dense_153_loss: 1.2515 - dense_154_loss: 1.2542 - dense_155_loss: 1.2536 - dense_156_loss: 1.2481 - dense_157_loss: 1.2511 - dense_158_loss: 1.2529 - dense_159_loss: 1.2509 - dense_160_loss: 1.2465 - dense_161_loss: 1.2542 - dense_162_loss: 1.2584 - dense_163_loss: 1.2487 - dense_164_loss: 1.2526 - dense_165_loss: 1.2554 - dense_85_accuracy: 0.5738 - dense_86_accuracy: 0.5760 - dense_87_accuracy: 0.5731 - dense_88_accuracy: 0.5754 - dense_89_accuracy: 0.5704 - dense_90_accuracy: 0.5700 - dense_91_accuracy: 0.5762 - dense_92_accuracy: 0.5768 - dense_93_accuracy: 0.5795 - dense_94_accuracy: 0.5728 - dense_95_accuracy: 0.5702 - dense_96_accuracy: 0.5807 - dense_97_accuracy: 0.5800 - dense_98_accuracy: 0.5796 - dense_99_accuracy: 0.5709 - dense_100_accuracy: 0.5738 - dense_101_accuracy: 0.5742 - dense_102_accuracy: 0.5768 - dense_103_accuracy: 0.5796 - dense_104_accuracy: 0.5854 - dense_105_accuracy: 0.5740 - dense_106_accuracy: 0.5700 - dense_107_accuracy: 0.5784 - dense_108_accuracy: 0.5739 - dense_109_accuracy: 0.5775 - dense_110_accuracy: 0.5744 - dense_111_accuracy: 0.5716 - dense_112_accuracy: 0.5820 - dense_113_accuracy: 0.5746 - dense_114_accuracy: 0.5700 - dense_115_accuracy: 0.5683 - dense_116_accuracy: 0.5747 - dense_117_accuracy: 0.5750 - dense_118_accuracy: 0.5676 - dense_119_accuracy: 0.5752 - dense_120_accuracy: 0.5740 - dense_121_accuracy: 0.5720 - dense_122_accuracy: 0.5824 - dense_123_accuracy: 0.5759 - dense_124_accuracy: 0.5733 - dense_125_accuracy: 0.5720 - dense_126_accuracy: 0.5701 - dense_127_accuracy: 0.5848 - dense_128_accuracy: 0.5841 - dense_129_accuracy: 0.5702 - dense_130_accuracy: 0.5702 - dense_131_accuracy: 0.5683 - dense_132_accuracy: 0.5857 - dense_133_accuracy: 0.5752 - dense_134_accuracy: 0.5792 - dense_135_accuracy: 0.5817 - dense_136_accuracy: 0.5856 - dense_137_accuracy: 0.5798 - dense_138_accuracy: 0.5769 - dense_139_accuracy: 0.5658 - dense_140_accuracy: 0.5767 - dense_141_accuracy: 0.5713 - dense_142_accuracy: 0.5831 - dense_143_accuracy: 0.5800 - dense_144_accuracy: 0.5720 - dense_145_accuracy: 0.5646 - dense_146_accuracy: 0.5714 - dense_147_accuracy: 0.5643 - dense_148_accuracy: 0.5771 - dense_149_accuracy: 0.5736 - dense_150_accuracy: 0.5718 - dense_151_accuracy: 0.5793 - dense_152_accuracy: 0.5805 - dense_153_accuracy: 0.5783 - dense_154_accuracy: 0.5713 - dense_155_accuracy: 0.5693 - dense_156_accuracy: 0.5763 - dense_157_accuracy: 0.5728 - dense_158_accuracy: 0.5743 - dense_159_accuracy: 0.5787 - dense_160_accuracy: 0.5816 - dense_161_accuracy: 0.5690 - dense_162_accuracy: 0.5714 - dense_163_accuracy: 0.5835 - dense_164_accuracy: 0.5720 - dense_165_accuracy: 0.5751 - val_loss: 0.1787 - val_dense_85_loss: 0.0026 - val_dense_86_loss: 0.0023 - val_dense_87_loss: 0.0028 - val_dense_88_loss: 0.0021 - val_dense_89_loss: 0.0020 - val_dense_90_loss: 0.0018 - val_dense_91_loss: 0.0025 - val_dense_92_loss: 0.0020 - val_dense_93_loss: 0.0022 - val_dense_94_loss: 0.0018 - val_dense_95_loss: 0.0023 - val_dense_96_loss: 0.0027 - val_dense_97_loss: 0.0023 - val_dense_98_loss: 0.0020 - val_dense_99_loss: 0.0028 - val_dense_100_loss: 0.0019 - val_dense_101_loss: 0.0017 - val_dense_102_loss: 0.0022 - val_dense_103_loss: 0.0020 - val_dense_104_loss: 0.0018 - val_dense_105_loss: 0.0020 - val_dense_106_loss: 0.0028 - val_dense_107_loss: 0.0021 - val_dense_108_loss: 0.0024 - val_dense_109_loss: 0.0023 - val_dense_110_loss: 0.0020 - val_dense_111_loss: 0.0022 - val_dense_112_loss: 0.0020 - val_dense_113_loss: 0.0019 - val_dense_114_loss: 0.0025 - val_dense_115_loss: 0.0030 - val_dense_116_loss: 0.0018 - val_dense_117_loss: 0.0020 - val_dense_118_loss: 0.0019 - val_dense_119_loss: 0.0018 - val_dense_120_loss: 0.0023 - val_dense_121_loss: 0.0022 - val_dense_122_loss: 0.0020 - val_dense_123_loss: 0.0022 - val_dense_124_loss: 0.0022 - val_dense_125_loss: 0.0020 - val_dense_126_loss: 0.0033 - val_dense_127_loss: 0.0020 - val_dense_128_loss: 0.0022 - val_dense_129_loss: 0.0020 - val_dense_130_loss: 0.0022 - val_dense_131_loss: 0.0021 - val_dense_132_loss: 0.0018 - val_dense_133_loss: 0.0023 - val_dense_134_loss: 0.0021 - val_dense_135_loss: 0.0022 - val_dense_136_loss: 0.0023 - val_dense_137_loss: 0.0019 - val_dense_138_loss: 0.0019 - val_dense_139_loss: 0.0025 - val_dense_140_loss: 0.0019 - val_dense_141_loss: 0.0020 - val_dense_142_loss: 0.0026 - val_dense_143_loss: 0.0019 - val_dense_144_loss: 0.0028 - val_dense_145_loss: 0.0020 - val_dense_146_loss: 0.0029 - val_dense_147_loss: 0.0022 - val_dense_148_loss: 0.0025 - val_dense_149_loss: 0.0025 - val_dense_150_loss: 0.0023 - val_dense_151_loss: 0.0019 - val_dense_152_loss: 0.0024 - val_dense_153_loss: 0.0026 - val_dense_154_loss: 0.0018 - val_dense_155_loss: 0.0020 - val_dense_156_loss: 0.0020 - val_dense_157_loss: 0.0024 - val_dense_158_loss: 0.0023 - val_dense_159_loss: 0.0019 - val_dense_160_loss: 0.0022 - val_dense_161_loss: 0.0020 - val_dense_162_loss: 0.0021 - val_dense_163_loss: 0.0025 - val_dense_164_loss: 0.0021 - val_dense_165_loss: 0.0027 - val_dense_85_accuracy: 0.9999 - val_dense_86_accuracy: 1.0000 - val_dense_87_accuracy: 0.9999 - val_dense_88_accuracy: 1.0000 - val_dense_89_accuracy: 1.0000 - val_dense_90_accuracy: 1.0000 - val_dense_91_accuracy: 0.9999 - val_dense_92_accuracy: 1.0000 - val_dense_93_accuracy: 1.0000 - val_dense_94_accuracy: 1.0000 - val_dense_95_accuracy: 0.9999 - val_dense_96_accuracy: 0.9999 - val_dense_97_accuracy: 1.0000 - val_dense_98_accuracy: 0.9999 - val_dense_99_accuracy: 0.9998 - val_dense_100_accuracy: 1.0000 - val_dense_101_accuracy: 1.0000 - val_dense_102_accuracy: 1.0000 - val_dense_103_accuracy: 1.0000 - val_dense_104_accuracy: 1.0000 - val_dense_105_accuracy: 0.9999 - val_dense_106_accuracy: 0.9999 - val_dense_107_accuracy: 0.9999 - val_dense_108_accuracy: 0.9999 - val_dense_109_accuracy: 1.0000 - val_dense_110_accuracy: 0.9999 - val_dense_111_accuracy: 0.9999 - val_dense_112_accuracy: 1.0000 - val_dense_113_accuracy: 1.0000 - val_dense_114_accuracy: 1.0000 - val_dense_115_accuracy: 0.9998 - val_dense_116_accuracy: 1.0000 - val_dense_117_accuracy: 1.0000 - val_dense_118_accuracy: 1.0000 - val_dense_119_accuracy: 1.0000 - val_dense_120_accuracy: 0.9999 - val_dense_121_accuracy: 1.0000 - val_dense_122_accuracy: 1.0000 - val_dense_123_accuracy: 1.0000 - val_dense_124_accuracy: 1.0000 - val_dense_125_accuracy: 1.0000 - val_dense_126_accuracy: 0.9998 - val_dense_127_accuracy: 1.0000 - val_dense_128_accuracy: 1.0000 - val_dense_129_accuracy: 1.0000 - val_dense_130_accuracy: 1.0000 - val_dense_131_accuracy: 1.0000 - val_dense_132_accuracy: 1.0000 - val_dense_133_accuracy: 0.9999 - val_dense_134_accuracy: 1.0000 - val_dense_135_accuracy: 1.0000 - val_dense_136_accuracy: 1.0000 - val_dense_137_accuracy: 1.0000 - val_dense_138_accuracy: 1.0000 - val_dense_139_accuracy: 0.9999 - val_dense_140_accuracy: 1.0000 - val_dense_141_accuracy: 1.0000 - val_dense_142_accuracy: 0.9998 - val_dense_143_accuracy: 1.0000 - val_dense_144_accuracy: 0.9999 - val_dense_145_accuracy: 1.0000 - val_dense_146_accuracy: 0.9999 - val_dense_147_accuracy: 0.9999 - val_dense_148_accuracy: 0.9999 - val_dense_149_accuracy: 1.0000 - val_dense_150_accuracy: 1.0000 - val_dense_151_accuracy: 1.0000 - val_dense_152_accuracy: 0.9999 - val_dense_153_accuracy: 1.0000 - val_dense_154_accuracy: 1.0000 - val_dense_155_accuracy: 1.0000 - val_dense_156_accuracy: 1.0000 - val_dense_157_accuracy: 0.9999 - val_dense_158_accuracy: 0.9999 - val_dense_159_accuracy: 1.0000 - val_dense_160_accuracy: 1.0000 - val_dense_161_accuracy: 1.0000 - val_dense_162_accuracy: 1.0000 - val_dense_163_accuracy: 0.9999 - val_dense_164_accuracy: 1.0000 - val_dense_165_accuracy: 0.9999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass nÂ° 2 ...\n",
      "Epoch 1/2\n",
      " 70/313 [=====>........................] - ETA: 1:59 - loss: 2.2401 - dense_85_loss: 0.0326 - dense_86_loss: 0.0294 - dense_87_loss: 0.0295 - dense_88_loss: 0.0305 - dense_89_loss: 0.0301 - dense_90_loss: 0.0282 - dense_91_loss: 0.0274 - dense_92_loss: 0.0280 - dense_93_loss: 0.0329 - dense_94_loss: 0.0266 - dense_95_loss: 0.0263 - dense_96_loss: 0.0293 - dense_97_loss: 0.0276 - dense_98_loss: 0.0242 - dense_99_loss: 0.0313 - dense_100_loss: 0.0304 - dense_101_loss: 0.0271 - dense_102_loss: 0.0295 - dense_103_loss: 0.0315 - dense_104_loss: 0.0249 - dense_105_loss: 0.0275 - dense_106_loss: 0.0226 - dense_107_loss: 0.0286 - dense_108_loss: 0.0267 - dense_109_loss: 0.0304 - dense_110_loss: 0.0249 - dense_111_loss: 0.0288 - dense_112_loss: 0.0270 - dense_113_loss: 0.0256 - dense_114_loss: 0.0258 - dense_115_loss: 0.0273 - dense_116_loss: 0.0285 - dense_117_loss: 0.0239 - dense_118_loss: 0.0265 - dense_119_loss: 0.0268 - dense_120_loss: 0.0241 - dense_121_loss: 0.0297 - dense_122_loss: 0.0276 - dense_123_loss: 0.0294 - dense_124_loss: 0.0296 - dense_125_loss: 0.0264 - dense_126_loss: 0.0256 - dense_127_loss: 0.0243 - dense_128_loss: 0.0304 - dense_129_loss: 0.0277 - dense_130_loss: 0.0263 - dense_131_loss: 0.0287 - dense_132_loss: 0.0275 - dense_133_loss: 0.0257 - dense_134_loss: 0.0264 - dense_135_loss: 0.0300 - dense_136_loss: 0.0252 - dense_137_loss: 0.0249 - dense_138_loss: 0.0271 - dense_139_loss: 0.0311 - dense_140_loss: 0.0270 - dense_141_loss: 0.0300 - dense_142_loss: 0.0256 - dense_143_loss: 0.0280 - dense_144_loss: 0.0283 - dense_145_loss: 0.0280 - dense_146_loss: 0.0287 - dense_147_loss: 0.0281 - dense_148_loss: 0.0242 - dense_149_loss: 0.0260 - dense_150_loss: 0.0278 - dense_151_loss: 0.0267 - dense_152_loss: 0.0243 - dense_153_loss: 0.0270 - dense_154_loss: 0.0329 - dense_155_loss: 0.0279 - dense_156_loss: 0.0249 - dense_157_loss: 0.0291 - dense_158_loss: 0.0295 - dense_159_loss: 0.0242 - dense_160_loss: 0.0286 - dense_161_loss: 0.0306 - dense_162_loss: 0.0239 - dense_163_loss: 0.0269 - dense_164_loss: 0.0286 - dense_165_loss: 0.0275 - dense_85_accuracy: 0.9922 - dense_86_accuracy: 0.9916 - dense_87_accuracy: 0.9925 - dense_88_accuracy: 0.9925 - dense_89_accuracy: 0.9920 - dense_90_accuracy: 0.9924 - dense_91_accuracy: 0.9944 - dense_92_accuracy: 0.9936 - dense_93_accuracy: 0.9910 - dense_94_accuracy: 0.9937 - dense_95_accuracy: 0.9934 - dense_96_accuracy: 0.9913 - dense_97_accuracy: 0.9940 - dense_98_accuracy: 0.9949 - dense_99_accuracy: 0.9912 - dense_100_accuracy: 0.9913 - dense_101_accuracy: 0.9930 - dense_102_accuracy: 0.9926 - dense_103_accuracy: 0.9920 - dense_104_accuracy: 0.9940 - dense_105_accuracy: 0.9930 - dense_106_accuracy: 0.9954 - dense_107_accuracy: 0.9924 - dense_108_accuracy: 0.9939 - dense_109_accuracy: 0.9920 - dense_110_accuracy: 0.9950 - dense_111_accuracy: 0.9940 - dense_112_accuracy: 0.9939 - dense_113_accuracy: 0.9944 - dense_114_accuracy: 0.9933 - dense_115_accuracy: 0.9934 - dense_116_accuracy: 0.9933 - dense_117_accuracy: 0.9942 - dense_118_accuracy: 0.9931 - dense_119_accuracy: 0.9933 - dense_120_accuracy: 0.9945 - dense_121_accuracy: 0.9921 - dense_122_accuracy: 0.9927 - dense_123_accuracy: 0.9927 - dense_124_accuracy: 0.9924 - dense_125_accuracy: 0.9934 - dense_126_accuracy: 0.9940 - dense_127_accuracy: 0.9942 - dense_128_accuracy: 0.9919 - dense_129_accuracy: 0.9927 - dense_130_accuracy: 0.9933 - dense_131_accuracy: 0.9932 - dense_132_accuracy: 0.9933 - dense_133_accuracy: 0.9948 - dense_134_accuracy: 0.9941 - dense_135_accuracy: 0.9916 - dense_136_accuracy: 0.9949 - dense_137_accuracy: 0.9943 - dense_138_accuracy: 0.9934 - dense_139_accuracy: 0.9916 - dense_140_accuracy: 0.9929 - dense_141_accuracy: 0.9927 - dense_142_accuracy: 0.9936 - dense_143_accuracy: 0.9931 - dense_144_accuracy: 0.9920 - dense_145_accuracy: 0.9929 - dense_146_accuracy: 0.9931 - dense_147_accuracy: 0.9930 - dense_148_accuracy: 0.9946 - dense_149_accuracy: 0.9940 - dense_150_accuracy: 0.9933 - dense_151_accuracy: 0.9936 - dense_152_accuracy: 0.9944 - dense_153_accuracy: 0.9936 - dense_154_accuracy: 0.9913 - dense_155_accuracy: 0.9929 - dense_156_accuracy: 0.9945 - dense_157_accuracy: 0.9923 - dense_158_accuracy: 0.9929 - dense_159_accuracy: 0.9948 - dense_160_accuracy: 0.9922 - dense_161_accuracy: 0.9925 - dense_162_accuracy: 0.9951 - dense_163_accuracy: 0.9927 - dense_164_accuracy: 0.9927 - dense_165_accuracy: 0.9933"
     ]
    }
   ],
   "source": [
    "''' Early Stopping '''\n",
    "es = EarlyStopping(patience=2, verbose=1)\n",
    "\n",
    "i = 1\n",
    "for ep, dele in zip([1, 2, 3, 4, 6, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], [1, 2, 3, 4, 6, 8, 10, 12, 15, 20, 25, 30, 35, 40, 45, 50, 55]):\n",
    "\n",
    "    print('Pass nÂ° {} ...'.format(i))\n",
    "    i += 1\n",
    "    \n",
    "    ''' training '''\n",
    "    model.fit(del_digits(X_train, dele), [y_train[:, i, j, :] for i in range(9) for j in range(9)],\n",
    "              validation_data=(del_digits(X_train, dele), [y_train[:, i, j, :] for i in range(9) for j in range(9)]), \n",
    "              batch_size=128, epochs=ep, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Evaluating model '''\n",
    "q = X_test.argmax(3)  \n",
    "actual = y_test.argmax(3) + 1 \n",
    "\n",
    "''' make some guesses'''\n",
    "sg = batch_smart_solve(q, model)   \n",
    "\n",
    "''' get number of errors on each quizz '''\n",
    "de = diff(actual, sg)  \n",
    "\n",
    "'''portion of correct solved quizzes '''\n",
    "acc = (de == 0).mean()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Grid solved:\\t {} Correct ones:\\t {} Accuracy:\\t {}\"\"\".format(de.shape[0], (de==0).sum(), acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
